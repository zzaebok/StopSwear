{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jamo import h2j, j2hcj\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-4a3f57d5652e>:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = ['ㄷ', 'ㅏ', 'ㄴ', 'ㄱ', 'ㅜ', 'ㅎ', 'ㄹ', 'ㅇ', 'ㅂ', 'ㅓ', 'ㅈ', 'ㅣ', ' ',\n",
    " 'ㅡ', 'ㅢ', 'ㅁ', 'ㅗ', 'ㅅ', 'ㅔ', 'ㅕ', 'ㅑ', ';', 'B', 'J', '.', 'P', 'G',\n",
    " 'ㄸ', 'ㅟ', 'ㅃ', 'ㅌ', '[', '1', ':', '8', '2', '3', '0', ']', 'V', 'L',\n",
    " 'I', 'E', 'ㅋ', 'ㅖ', '(', 'ㅠ', ')', '5', 'ㅝ', 'ㅐ', 'ㅆ', \"'\", 'ㅀ', 'ㅊ',\n",
    " 't', 'x', 'ㅙ', 'ㅚ', 'ㅉ', 'ㅍ', 'ㅄ', '?', 'g', 'i', 'f', 'ㅛ', '6', '7', '☀',\n",
    " 'ㄲ', 'v', 's', 'ㅘ', '!', 'ㄶ', 'p', 'c', 'ㄼ', '\\u3000', 'k', '4', '9', ',',\n",
    " 'ㅞ', 'ㅒ', '“', '”', 'N', '‘', '’', 'T', 'O', 'a', 'r', 'm', 'S', '+', 'o', 'd',\n",
    " 'l', 'u', '·', '~', '/', 'ㄻ', '^', 'ㄺ', 'e', 'n', 'A', '-', 'D', '&', 'C',\n",
    " 'F', 'j', 'M', 'K', '\"', '_', 'Z', 'X', 'U', '…', 'ㄾ', 'w', '=', 'z',\n",
    " '>', '<', 'b', 'H', '@', '*', 'W', 'y', 'h', 'R', '%', 'ㄽ', '．',\n",
    " 'ｊ', 'ｐ', 'ｇ', 'ㄵ', '{', '}', 'q', 'Y', 'Q',\n",
    " '$', 'ㄿ', '？', 'ㆍ', 'ㄳ', '⋅', '—']\n",
    "\n",
    "vocab_dict = {c: i for i, c in enumerate(vocab, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK = 0\n",
    "PAD = len(vocab_dict) + 1\n",
    "\n",
    "def preprocessing(char_list):\n",
    "    ret = [vocab_dict[char] if char in vocab_dict else UNK for char in char_list]\n",
    "    if len(ret) <= 100:\n",
    "        ret += [PAD] * (100 - len(ret))\n",
    "    else:\n",
    "        ret = ret[:100]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normals = pd.read_csv('models/normals.txt', sep='\\t', names=['text', 'label'])\n",
    "df_swears = pd.read_csv('models/swears.txt', sep='\\t', names=['text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normals['text'] = df_normals['text'].apply(lambda x: j2hcj(h2j(x)))\n",
    "df_swears['text'] = df_swears['text'].apply(lambda x: j2hcj(h2j(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normals['text'] = df_normals['text'].apply(lambda x: preprocessing(list(x)))\n",
    "df_swears['text'] = df_swears['text'].apply(lambda x: preprocessing(list(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normals_sampled = df_normals.sample(n=len(df_swears), random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[4, 17, 8, 21, 8, 8, 12, 13, 8, 12, 9, 13, 11,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[9, 51, 31, 14, 7, 61, 12, 7, 1, 14, 82, 13, 1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[3, 2, 8, 12, 16, 10, 4, 8, 14, 7, 18, 5, 7, 1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[3, 2, 11, 5, 8, 8, 19, 13, 38, 25, 49, 3, 2, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[44, 17, 7, 8, 17, 9, 13, 7, 12, 16, 2, 18, 14...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5573</th>\n",
       "      <td>[4, 19, 18, 4, 19, 7, 13, 11, 9, 2, 9, 1, 14, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5574</th>\n",
       "      <td>[4, 19, 18, 4, 51, 7, 1, 17, 13, 11, 17, 55, 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5575</th>\n",
       "      <td>[4, 19, 18, 8, 51, 16, 13, 8, 47, 11, 10, 13, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5576</th>\n",
       "      <td>[11, 17, 11, 3, 47, 9, 12, 13, 55, 17, 9, 17, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5577</th>\n",
       "      <td>[6, 51, 4, 4, 2, 16, 9, 20, 7, 18, 2, 13, 9, 2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5578 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     [4, 17, 8, 21, 8, 8, 12, 13, 8, 12, 9, 13, 11,...      0\n",
       "1     [9, 51, 31, 14, 7, 61, 12, 7, 1, 14, 82, 13, 1...      0\n",
       "2     [3, 2, 8, 12, 16, 10, 4, 8, 14, 7, 18, 5, 7, 1...      0\n",
       "3     [3, 2, 11, 5, 8, 8, 19, 13, 38, 25, 49, 3, 2, ...      0\n",
       "4     [44, 17, 7, 8, 17, 9, 13, 7, 12, 16, 2, 18, 14...      0\n",
       "...                                                 ...    ...\n",
       "5573  [4, 19, 18, 4, 19, 7, 13, 11, 9, 2, 9, 1, 14, ...      1\n",
       "5574  [4, 19, 18, 4, 51, 7, 1, 17, 13, 11, 17, 55, 1...      1\n",
       "5575  [4, 19, 18, 8, 51, 16, 13, 8, 47, 11, 10, 13, ...      1\n",
       "5576  [11, 17, 11, 3, 47, 9, 12, 13, 55, 17, 9, 17, ...      1\n",
       "5577  [6, 51, 4, 4, 2, 16, 9, 20, 7, 18, 2, 13, 9, 2...      1\n",
       "\n",
       "[5578 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total = pd.concat([df_normals_sampled, df_swears], ignore_index=True)\n",
    "df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df_total, test_size=0.2, stratify=df_total['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>[16, 51, 9, 12, 3, 17, 4, 12, 93, 89, 159, 159...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4745</th>\n",
       "      <td>[11, 67, 11, 18, 47, 13, 92, 97, 159, 159, 159...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>[9, 12, 55, 55, 51, 6, 51, 1, 14, 3, 7, 2, 6, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329</th>\n",
       "      <td>[3, 2, 3, 13, 31, 14, 3, 12, 11, 74, 13, 16, 5...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>[4, 2, 9, 11, 2, 4, 12, 13, 4, 5, 8, 4, 14, 16...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2233</th>\n",
       "      <td>[9, 19, 3, 31, 5, 13, 9, 17, 31, 14, 13, 31, 5...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>[4, 14, 3, 1, 19, 13, 18, 14, 16, 13, 28, 17, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2971</th>\n",
       "      <td>[7, 19, 9, 12, 8, 2, 11, 10, 11, 31, 51, 8, 8,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>[11, 2, 7, 2, 3, 12, 4, 2, 13, 8, 50, 3, 7, 5,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110</th>\n",
       "      <td>[8, 20, 4, 12, 3, 13, 44, 17, 3, 18, 17, 7, 8,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4462 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "374   [16, 51, 9, 12, 3, 17, 4, 12, 93, 89, 159, 159...      0\n",
       "4745  [11, 67, 11, 18, 47, 13, 92, 97, 159, 159, 159...      1\n",
       "204   [9, 12, 55, 55, 51, 6, 51, 1, 14, 3, 7, 2, 6, ...      0\n",
       "2329  [3, 2, 3, 13, 31, 14, 3, 12, 11, 74, 13, 16, 5...      0\n",
       "832   [4, 2, 9, 11, 2, 4, 12, 13, 4, 5, 8, 4, 14, 16...      0\n",
       "...                                                 ...    ...\n",
       "2233  [9, 19, 3, 31, 5, 13, 9, 17, 31, 14, 13, 31, 5...      0\n",
       "1615  [4, 14, 3, 1, 19, 13, 18, 14, 16, 13, 28, 17, ...      0\n",
       "2971  [7, 19, 9, 12, 8, 2, 11, 10, 11, 31, 51, 8, 8,...      1\n",
       "1572  [11, 2, 7, 2, 3, 12, 4, 2, 13, 8, 50, 3, 7, 5,...      0\n",
       "2110  [8, 20, 4, 12, 3, 13, 44, 17, 3, 18, 17, 7, 8,...      0\n",
       "\n",
       "[4462 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, ytrain = np.vstack(df_train['text']), tf.one_hot(np.array(df_train['label']), depth=2)\n",
    "xtest, ytest = np.vstack(df_test['text']), tf.one_hot(np.array(df_test['label']), depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((xtrain,ytrain)).batch(32)\n",
    "test_ds =tf.data.Dataset.from_tensor_slices((xtest,ytest)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Model(tf.keras.Model):\n",
    "#     def __init__(self):\n",
    "#         super(Model, self).__init__()\n",
    "#         self.emb = tf.keras.layers.Embedding(input_dim=160, output_dim=64, input_length=100)\n",
    "#         self.conv1 = tf.keras.layers.Conv1D(64, 5, activation='relu', input_shape=(100,64))\n",
    "#         self.pool1 = tf.keras.layers.MaxPooling1D(pool_size=2, strides=2)\n",
    "#         self.conv2 = tf.keras.layers.Conv1D(32, 5, activation='relu', input_shape=(96,32))\n",
    "#         self.pool2 = tf.keras.layers.MaxPooling1D(pool_size=2, strides=2)\n",
    "#         self.conv3 = tf.keras.layers.Conv1D(16, 5, activation='relu', input_shape=(92,16))\n",
    "#         self.pool3 = tf.keras.layers.MaxPooling1D(pool_size=2, strides=2)\n",
    "#         self.flat = tf.keras.layers.Flatten(input_shape=(84, 8))\n",
    "#         self.dense = tf.keras.layers.Dense(128, activation='relu')\n",
    "#         self.classifier = tf.keras.layers.Dense(2, activation='softmax')\n",
    "    \n",
    "#     def call(self, x):\n",
    "#         x = self.emb(x)\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.pool1(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.pool2(x)\n",
    "#         x = self.conv3(x)\n",
    "#         x = self.pool3(x)\n",
    "#         x = self.flat(x)\n",
    "#         x = self.dense(x)\n",
    "#         return self.classifier(x)\n",
    "    \n",
    "# model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.emb = tf.keras.layers.Embedding(input_dim=160, output_dim=128, input_length=100)\n",
    "        \n",
    "        self.conv1_a = tf.keras.layers.Conv1D(128, 5, activation='relu', input_shape=(100, 128), padding='same')\n",
    "        self.conv1_b = tf.keras.layers.Conv1D(128, 5, activation='relu', input_shape=(100, 128), padding='same')\n",
    "        self.conv1_c = tf.keras.layers.Conv1D(128, 5, activation='relu', input_shape=(100, 128))\n",
    "        \n",
    "        self.conv2_a = tf.keras.layers.Conv1D(128, 5, activation='relu', input_shape=(48, 128), padding='same')\n",
    "        self.conv2_b = tf.keras.layers.Conv1D(128, 5, activation='relu', input_shape=(48, 128), padding='same')\n",
    "        self.conv2_c = tf.keras.layers.Conv1D(128, 5, activation='relu', input_shape=(48, 128))\n",
    "        \n",
    "#         self.conv3_a = tf.keras.layers.Conv1D(32, 5, activation='relu', input_shape=(92, 32), padding='same')\n",
    "#         self.conv3_b = tf.keras.layers.Conv1D(32, 5, activation='relu', input_shape=(92, 32), padding='same')\n",
    "#         self.conv3_c = tf.keras.layers.Conv1D(32, 5, activation='relu', input_shape=(92, 32))\n",
    "        \n",
    "        self.conv_a_q = tf.keras.layers.Conv1D(128, 5, activation='elu', input_shape=(22, 128))\n",
    "        self.conv_a_k = tf.keras.layers.Conv1D(128, 5, activation='elu', input_shape=(22, 128))\n",
    "        self.conv_a_v = tf.keras.layers.Conv1D(128, 5, activation='elu', input_shape=(22, 128))\n",
    "        \n",
    "        self.conv_b_q = tf.keras.layers.Conv1D(128, 5, activation='elu', input_shape=(22, 128))\n",
    "        self.conv_b_k = tf.keras.layers.Conv1D(128, 5, activation='elu', input_shape=(22, 128))\n",
    "        self.conv_b_v = tf.keras.layers.Conv1D(128, 5, activation='tanh', input_shape=(22, 128))\n",
    "        # 88x16 => 22x128\n",
    "\n",
    "        self.pool = tf.keras.layers.MaxPooling1D(pool_size=2, strides=2)\n",
    "        \n",
    "        # self.flat = tf.keras.layers.Flatten(input_shape=(32, 16))\n",
    "        self.dense = tf.keras.layers.Dense(32, activation='relu')\n",
    "        #self.dense2 = tf.keras.layers.Dense(128, activation='relu')\n",
    "        self.classifier = tf.keras.layers.Dense(2, activation='softmax')\n",
    "        \n",
    "    def call(self, x):\n",
    "        # [batch, 100] -> [batch, 100, 128]\n",
    "        x = self.emb(x)\n",
    "        #print(x.shape)\n",
    "        # [batch, 100, 128] -> [batch, 96, 128]\n",
    "        x = self.conv1_a(x)\n",
    "        x = self.conv1_b(x)\n",
    "        x = self.conv1_c(x)\n",
    "        #print(x.shape)\n",
    "        # [batch, 96, 128] -> [batch, 48, 128]\n",
    "        x = self.pool(x)\n",
    "        #print(x.shape)\n",
    "        # [batch, 48, 128] -> [batch, 44, 128]\n",
    "        x = self.conv2_a(x)\n",
    "        x = self.conv2_b(x)\n",
    "        x = self.conv2_c(x)\n",
    "        #print(x.shape)\n",
    "        # [batch, 44, 128] -> [batch, 22, 128]\n",
    "        x = self.pool(x)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        # [batch, 22, 128] -> [batch, 128]\n",
    "        x_a_q = self.conv_a_q(x)\n",
    "        x_a_k = self.conv_a_k(x)\n",
    "        x_a_v = self.conv_a_v(x)\n",
    "        scaled_dot_a = tf.math.reduce_sum(tf.math.multiply(x_a_q, x_a_k), axis=2) / math.sqrt(128)\n",
    "        a_a = tf.expand_dims(tf.nn.softmax(scaled_dot_a, axis=1), axis=-1)\n",
    "        x_a = tf.math.reduce_sum(tf.math.multiply(a_a, x_a_v), axis=1)\n",
    "        #print(x_a.shape)\n",
    "        \n",
    "        x_b_q = self.conv_b_q(x)\n",
    "        x_b_k = self.conv_b_k(x)\n",
    "        x_b_v = self.conv_b_v(x)\n",
    "        scaled_dot_b = tf.math.reduce_sum(tf.math.multiply(x_b_q, x_b_k), axis=2) / math.sqrt(128)\n",
    "        a_b = tf.expand_dims(tf.nn.softmax(scaled_dot_b, axis=1), axis=-1)\n",
    "        x_b = tf.math.reduce_sum(tf.math.multiply(a_b, x_b_v), axis=1)\n",
    "        \n",
    "        x = tf.math.multiply(x_a, x_b)\n",
    "        x = self.dense(x)\n",
    "        return self.classifier(x)\n",
    "    \n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.BinaryAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.BinaryAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(documents, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(documents)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(documents, labels):\n",
    "    predictions = model(documents)\n",
    "    loss = loss_object(labels, predictions)\n",
    "    \n",
    "    test_loss(loss)\n",
    "    test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": "2 root error(s) found.\n  (0) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node model/conv1d/conv1d (defined at <ipython-input-15-5f2c6d55368f>:39) ]]\n\t [[gradient_tape/model/embedding/embedding_lookup/Reshape/_18]]\n  (1) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node model/conv1d/conv1d (defined at <ipython-input-15-5f2c6d55368f>:39) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_step_2319]\n\nFunction call stack:\ntrain_step -> train_step\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-fb078c27a05b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: 2 root error(s) found.\n  (0) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node model/conv1d/conv1d (defined at <ipython-input-15-5f2c6d55368f>:39) ]]\n\t [[gradient_tape/model/embedding/embedding_lookup/Reshape/_18]]\n  (1) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node model/conv1d/conv1d (defined at <ipython-input-15-5f2c6d55368f>:39) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_step_2319]\n\nFunction call stack:\ntrain_step -> train_step\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1000\n",
    "\n",
    "early_stop = 0\n",
    "prev_best = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for documents, labels in train_ds:\n",
    "        train_step(documents, labels)\n",
    "    for documents, labels in test_ds:\n",
    "        test_step(documents, labels)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        if test_accuracy.result() > prev_best:\n",
    "            prev_best = test_accuracy.result()\n",
    "            early_stop = 0\n",
    "            model.save('models/model')\n",
    "        else:\n",
    "            early_stop += 1\n",
    "            if early_stop == 4:\n",
    "                break\n",
    "        template = \"[EPOCH {}/{}], LOSS: {}, ACCURACY: {}, TEST_LOSS: {}, TEST_ACCURACY: {}\"\n",
    "        print(template.format(\n",
    "            epoch+1,\n",
    "            EPOCHS,\n",
    "            train_loss.result(),\n",
    "            train_accuracy.result()*100,\n",
    "            test_loss.result(),\n",
    "            test_accuracy.result()*100\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text=None):\n",
    "    if text is None:\n",
    "        text = input()\n",
    "    x = j2hcj(h2j(text))\n",
    "    x = preprocessing(list(x))\n",
    "    prediction = model.predict(np.array([x]))\n",
    "    if prediction[0][0] > prediction[0][1]:\n",
    "        print('정상입니다.')\n",
    "    else:\n",
    "        print('욕입니다.')\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "욕입니다.\n",
      "[[1.5799628e-15 1.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "predict('똥맛')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model('models/model')\n",
    "#converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# converter.experimental_new_converter = True\n",
    "# converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('models/model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
